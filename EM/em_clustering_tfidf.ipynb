{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "892cf0a6",
   "metadata": {},
   "source": [
    "# EM (GMM) Text Clustering Using TF-IDF (Optimized Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0121424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, cohen_kappa_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17b1271",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f593887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../processed_data.csv\")\n",
    "\n",
    "texts = data[\"Cleaned_Content\"].astype(str)\n",
    "true_labels = data[\"Label\"]\n",
    "\n",
    "tokenized_texts = [doc.split() for doc in texts]\n",
    "\n",
    "print(\"Dataset size:\", len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbb6b6e",
   "metadata": {},
   "source": [
    "## TF-IDF Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fb8b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1,2),\n",
    "    min_df=5,\n",
    "    max_df=0.7,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X = tfidf.fit_transform(texts).toarray()\n",
    "\n",
    "print(\"TF-IDF Shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910c1ddf",
   "metadata": {},
   "source": [
    "## Scaling + PCA (Important for GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad36e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=100, random_state=42)\n",
    "X_reduced = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"Reduced Shape:\", X_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ba233e",
   "metadata": {},
   "source": [
    "## EM / GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = len(np.unique(true_labels))\n",
    "\n",
    "gmm = GaussianMixture(\n",
    "    n_components=n_clusters,\n",
    "    covariance_type='diag',   # improved stability\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pred_clusters = gmm.fit_predict(X_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90c028e",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f954dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sil = silhouette_score(X_reduced, pred_clusters)\n",
    "print(\"Silhouette Score:\", sil)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "true_encoded = encoder.fit_transform(true_labels)\n",
    "\n",
    "kappa = cohen_kappa_score(true_encoded, pred_clusters)\n",
    "print(\"Kappa Score:\", kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33b7183",
   "metadata": {},
   "source": [
    "## Confusion Matrix (7.1 Disagreement Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b65523",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_encoded, pred_clusters)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - GMM (TF-IDF)\")\n",
    "plt.xlabel(\"Predicted Cluster\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e55ae7e",
   "metadata": {},
   "source": [
    "## Coherence Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee9915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(tokenized_texts)\n",
    "\n",
    "cluster_topics = []\n",
    "\n",
    "for c in range(n_clusters):\n",
    "    cluster_docs = texts[pred_clusters == c]\n",
    "    if len(cluster_docs) > 0:\n",
    "        vectorizer = CountVectorizer(\n",
    "            stop_words=\"english\",\n",
    "            max_features=10\n",
    "        )\n",
    "        X_counts = vectorizer.fit_transform(cluster_docs)\n",
    "        words = vectorizer.get_feature_names_out()\n",
    "        cluster_topics.append(list(words))\n",
    "\n",
    "coherence_model = CoherenceModel(\n",
    "    topics=cluster_topics,\n",
    "    texts=tokenized_texts,\n",
    "    dictionary=dictionary,\n",
    "    coherence='c_v'\n",
    ")\n",
    "\n",
    "coherence = coherence_model.get_coherence()\n",
    "print(\"Coherence Score:\", coherence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92330b87",
   "metadata": {},
   "source": [
    "## PCA (2D) for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ce21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_vis = PCA(n_components=2, random_state=42)\n",
    "X_vis = pca_vis.fit_transform(X_reduced)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "scatter = plt.scatter(\n",
    "    X_vis[:,0],\n",
    "    X_vis[:,1],\n",
    "    c=pred_clusters,\n",
    "    cmap=\"viridis\",\n",
    "    s=25\n",
    ")\n",
    "\n",
    "plt.title(\"GMM Clustering (TF-IDF + PCA)\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.colorbar(scatter)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c4b753",
   "metadata": {},
   "source": [
    "## Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae21aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "linked = linkage(X_reduced[:200], method='ward')\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "dendrogram(linked, truncate_mode=\"level\", p=5)\n",
    "plt.title(\"Hierarchical Dendrogram (TF-IDF)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137bef46",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b0c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Predicted\"] = pred_clusters\n",
    "data[\"True\"] = true_encoded\n",
    "\n",
    "errors = data[data[\"Predicted\"] != data[\"True\"]]\n",
    "\n",
    "print(\"Misclustered Samples:\", len(errors))\n",
    "\n",
    "if len(errors) > 0:\n",
    "    vectorizer = CountVectorizer(\n",
    "        stop_words=\"english\",\n",
    "        max_features=10\n",
    "    )\n",
    "    X_err = vectorizer.fit_transform(\n",
    "        errors[\"Cleaned_Content\"]\n",
    "    )\n",
    "    print(\"Top confusing words:\")\n",
    "    print(vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\n===== PIPELINE FINISHED SUCCESSFULLY =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04b72b3",
   "metadata": {},
   "source": [
    "## Error Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc2ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_analysis(model_name, data, true_encoded, pred_clusters, texts, encoder):\n",
    "    print(f\"\\n===== ERROR ANALYSIS: {model_name} =====\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(true_encoded, pred_clusters)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted Cluster\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Category agreement\n",
    "    label_names = encoder.classes_\n",
    "    category_agreement = {}\n",
    "\n",
    "    for i, label in enumerate(label_names):\n",
    "        correct = cm[i, i]\n",
    "        total = cm[i].sum()\n",
    "        acc = correct / total if total > 0 else 0\n",
    "        category_agreement[label] = acc\n",
    "\n",
    "    print(\"\\nCategory-wise agreement:\")\n",
    "    for k, v in category_agreement.items():\n",
    "        print(k, round(v, 3))\n",
    "\n",
    "    # Worst category\n",
    "    worst_category = min(category_agreement, key=category_agreement.get)\n",
    "    print(\"Worst clustered category:\", worst_category)\n",
    "\n",
    "    worst_index = list(label_names).index(worst_category)\n",
    "\n",
    "    misclassified = data[\n",
    "        (true_encoded == worst_index) &\n",
    "        (pred_clusters != worst_index)\n",
    "    ]\n",
    "\n",
    "    print(\"Misclassified samples:\", len(misclassified))\n",
    "\n",
    "    # Top confusing words\n",
    "    if len(misclassified) > 0:\n",
    "        vectorizer = CountVectorizer(\n",
    "            stop_words=\"english\",\n",
    "            max_features=15\n",
    "        )\n",
    "        X_err = vectorizer.fit_transform(misclassified[\"Cleaned_Content\"])\n",
    "        top_words = vectorizer.get_feature_names_out()\n",
    "\n",
    "        print(\"Top confusing words:\")\n",
    "        print(top_words)\n",
    "\n",
    "        # Save to txt file\n",
    "        with open(f\"Error_{model_name}_TopWords.txt\", \"w\") as f:\n",
    "            f.write(\"Worst Category: \" + worst_category + \"\\n\")\n",
    "            f.write(\"Misclassified Samples: \" + str(len(misclassified)) + \"\\n\\n\")\n",
    "            f.write(\"Top Confusing Words:\\n\")\n",
    "            for w in top_words:\n",
    "                f.write(w + \"\\n\")\n",
    "\n",
    "error_analysis(\"TFIDF_GMM\", data, true_encoded, pred_clusters, texts, encoder)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
